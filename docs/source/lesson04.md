# Lesson 04 - Regress√£o Log√≠stica

A principal diferen√ßa entre o modelo log√≠stico e o modelo linear √© que o desfecho √© uma vari√°vel bin√°ria (dicot√≥mica).

A regress√£o log√≠stica permite estimar a probabilidade associada √† ocorr√™ncia de um determinado evento, dado um conjunto de covari√°veis.

## Conceitos-chave:

- **Vari√°vel Bin√°ria**: No modelo log√≠stico, a vari√°vel dependente assume apenas dois valores (por exemplo, 0 e 1), indicando a aus√™ncia ou presen√ßa de uma caracter√≠stica ou resultado.
- **Estimativa de Probabilidade**: A regress√£o log√≠stica estima a probabilidade de ocorr√™ncia de um evento com base nas vari√°veis independentes ou covari√°veis.

## Fun√ß√µes Utilizadas para Modelar Vari√°veis Dicot√≥micas:

Existem v√°rias fun√ß√µes com a forma "S" e limitadas entre 0 e 1. As mais utilizadas para modelar vari√°veis dicot√≥micas s√£o:

- **Logit**: A fun√ß√£o logit √© utilizada na regress√£o log√≠stica e √© definida como:

  \[
  \text{Logit: } P(y_i = 1 | x_i) = \frac{\exp(\beta_0 + \beta_1 x_i)}{1 + \exp(\beta_0 + \beta_1 x_i)}
  \]

  A fun√ß√£o logit "estica" a forma em "S" para uma linha reta:

  \[
  \log \left( \frac{P(y_i = 1 | x_i)}{1 - P(y_i = 1 | x_i)} \right) = \beta_0 + \beta_1 x_i
  \]

- **Probit**: A fun√ß√£o probit √© outra abordagem para modelar vari√°veis dicot√≥micas e √© definida como:

  \[
  \text{Probit: } P(y_i = 1 | x_i) = \Phi^{-1} (\beta_0 + \beta_1 x_i)
  \]

  onde \(\Phi(z)\) √© a fun√ß√£o de distribui√ß√£o cumulativa da distribui√ß√£o normal padr√£o:

  \[
  \Phi(z) = \int_{-\infty}^{z} \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}} dt
  \]

## Interpreta√ß√£o do Modelo

> ### üí° **Interpreta√ß√£o do Modelo:**
> A regress√£o log√≠stica permite calcular a probabilidade do desfecho (evento) para um determinado valor da covari√°vel. Isso significa que, dado um conjunto de covari√°veis, podemos estimar a probabilidade de ocorr√™ncia de um evento espec√≠fico.

## Coeficientes

Vamos considerar o caso em que \(X\) √© uma vari√°vel dicot√≥mica (assume valores 0 e 1). Assumindo o modelo:

\[
P(y_i = 1 | x_i) = \frac{\exp(\beta_0 + \beta_1 x_i)}{1 + \exp(\beta_0 + \beta_1 x_i)}
\]

Designamos *odds* como o quociente entre a probabilidade do desfecho ocorrer e a probabilidade de sua n√£o-ocorr√™ncia. Portanto, a transforma√ß√£o logit nada mais √© do que o logaritmo de uma *odds*:

\[
\text{odds} = \frac{P(y_i = 1 | x_i)}{1 - P(y_i = 1 | x_i)}
\]

\[
\log(\text{odds}) = \beta_0 + \beta_1 x_i
\]

Os coeficientes de regress√£o log√≠stica (\(\beta\)) podem ent√£o ser interpretados como raz√µes de *odds* (log). Ou seja, as *odds* de \(y = 1\) aumentam \(\exp(\beta)\) vezes, quando a vari√°vel \(x\) aumenta em uma unidade (isto tamb√©m √© v√°lido para \(x\) cont√≠nua).

## Exemplo de Interpreta√ß√£o dos Coeficientes

> ### üí° **Interpreta√ß√£o dos Coeficientes:**
> Em nosso exemplo, um aumento de uma unidade em \(X\) corresponde a um aumento de \(e^{\beta} = 1.117\) vezes nas *odds* do desfecho ocorrer.
>
> Aten√ß√£o: um aumento de 10 unidades em \(X\) corresponde a um aumento de \(e^{0.111 \times 10} = e^{1.11} = 3.03\) nas *odds* do desfecho ocorrer, e n√£o \(1.117 \times 10 = 11.17\).

## Infer√™ncia

> ### üîç **Infer√™ncia:**
> Existem v√°rias formas diferentes de fazer infer√™ncia em regress√£o log√≠stica, incluindo:
>
> - **Intervalos de Confian√ßa (IC):** Intervalos de confian√ßa para os coeficientes de regress√£o podem ser obtidos usando a distribui√ß√£o assint√≥tica dos estimadores de m√°xima verossimilhan√ßa.
>
>   \[
>   IC_{95\%}(\beta_1) = [ \hat{\beta}_1 - 1.96 \times SE; \hat{\beta}_1 + 1.96 \times SE ]
>   \]
>
>   Tamb√©m podemos obter o IC para \(\exp(\beta)\), ou seja, o IC para a raz√£o de *odds*.
>
> - **Testes de Hip√≥teses:** Existem v√°rios testes de hip√≥teses para verificar se os coeficientes de regress√£o s√£o diferentes de 0:
>
>   - **Teste de Wald:** Baseado na distribui√ß√£o assint√≥tica do estimador.
>
>     - **H0: \(\beta_1 = 0\)**
>
>   - **Teste de Raz√£o de Verossimilhan√ßa:** Compara a verossimilhan√ßa de um modelo com a covari√°vel (modelo A) e sem a covari√°vel (modelo B).

## Varia√ß√£o

> ### üìä **Varia√ß√£o:**
> Existem medidas de "Pseudo" \(R^2\) que avaliam a quantidade de varia√ß√£o explicada pelo modelo. Estas incluem:
>
> - **Pseudo \(R^2\) de Cox & Snell:** Baseado na log-verossimilhan√ßa do modelo. Tem um valor m√°ximo te√≥rico (para o modelo "perfeito") inferior a 1.
> - **Pseudo \(R^2\) de Nagelkerke:** Baseado no anterior, mas ajustado para que o valor m√°ximo te√≥rico seja 1.

## Regress√£o Log√≠stica M√∫ltipla

A extens√£o do modelo de regress√£o log√≠stica para m√∫ltiplas covari√°veis √© imediata:
Os coeficientes s√£o interpretados como raz√µes de *odds* ajustadas para outras covari√°veis.

Existem dois pontos-chave neste processo:

1. **Escolha das Vari√°veis a Integrar no Modelo:**
   - A sele√ß√£o cuidadosa das vari√°veis que ser√£o inclu√≠das no modelo √© crucial para garantir a validade e a precis√£o das infer√™ncias.

2. **Avalia√ß√£o da Adequa√ß√£o do Modelo:**
   - **Avalia√ß√£o Geral:** Verifica√ß√£o da qualidade do ajuste do modelo em rela√ß√£o aos dados observados.
   - **Avalia√ß√£o das Covari√°veis Individuais:** An√°lise do impacto e signific√¢ncia de cada covari√°vel no modelo.
